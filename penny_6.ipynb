{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f3dfb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c35846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "ENVIR = 'indoor'\n",
    "LAYERS = 2\n",
    "BATCHES = 5\n",
    "CHANNELS = 2\n",
    "\n",
    "# image parameters\n",
    "IMG_HEIGHT = 32\n",
    "IMG_WIDTH = IMG_HEIGHT\n",
    "IMG_DIM = IMG_HEIGHT * IMG_WIDTH * CHANNELS\n",
    "IMG_QUBITS = int(np.log2(IMG_DIM))\n",
    "\n",
    "# compressed parameters\n",
    "COM_HEIGHT = 16\n",
    "COM_WIDTH = COM_HEIGHT \n",
    "COM_DIM = COM_HEIGHT * COM_WIDTH * CHANNELS\n",
    "COM_QUBITS = int(np.log2(COM_DIM))\n",
    "\n",
    "ALL_QUBITS = IMG_QUBITS + 1\n",
    "ANC_QUBITS = IMG_QUBITS - COM_QUBITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b76aad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicalNN(nn.Module):\n",
    "    ''' 构造经典压缩神经网络 '''\n",
    "    def __init__(self, channels, img_height, com_height):\n",
    "        super().__init__()\n",
    "        self.img_dim = channels * img_height**2\n",
    "        self.com_dim = channels * com_height**2\n",
    "        self.conv = nn.Conv2d(in_channels=channels, out_channels=2, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.dense_encode = nn.Linear(in_features=self.img_dim, out_features=self.com_dim)\n",
    "        self.bn1d = nn.BatchNorm1d(num_features=channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' 定义经典压缩层 '''\n",
    "        x = self.conv(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = x.reshape((x.shape[0], 1, self.img_dim))\n",
    "        x = self.dense_encode(x)\n",
    "        x = 2 * self.bn1d(x)  # 注意在这里完成了乘2\n",
    "        return x\n",
    "\n",
    "\n",
    "def frqi_encoder(qubits, params, target=0):\n",
    "    ''' construct the FRQI encoding circuit '''\n",
    "    for index in range(2**qubits):\n",
    "        binary_str = bin(index)[2:].zfill(qubits)\n",
    "        bits = [int(bit) for bit in binary_str]\n",
    "        bits.reverse()  # 原地逆序，高位在右，作用于序数大的比特位\n",
    "        qml.ctrl(qml.RY, control=range(1, qubits + 1), control_values=bits)(params[index], wires=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e14d620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coe = [-1]\n",
    "obs_list = [qml.PauliZ(0)]\n",
    "hamiltonian = qml.Hamiltonian(coe, observables=obs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "556827ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit', wires=ALL_QUBITS)\n",
    "\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def frqi_circuit(com_params, img_params, asz_params):\n",
    "    ''' construct the complete quantum circuit '''\n",
    "    for i in range(1, COM_QUBITS + 1):\n",
    "        qml.Hadamard(wires=i)\n",
    "    frqi_encoder(COM_QUBITS, com_params)\n",
    "    qml.StronglyEntanglingLayers(weights=asz_params, wires=range(ALL_QUBITS))\n",
    "    frqi_encoder(IMG_QUBITS, img_params)\n",
    "    return qml.expval(hamiltonian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "487ac811",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridNN(nn.Module):\n",
    "    ''' 把上面定义的经典神经网络和量子神经网络组装成完整神经网络 '''\n",
    "    def __init__(self, classical_nn):\n",
    "        super().__init__()\n",
    "        self.classical_nn = classical_nn\n",
    "        self.asz_params = np.random.uniform(0, np.pi, size=(LAYERS, ALL_QUBITS, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' 在量子线路前，加上经典压缩网络 '''\n",
    "        com_params = self.classical_nn(x)\n",
    "        reverse_x = (-1) * x\n",
    "        loss = frqi_circuit(com_params, reverse_x, self.asz_params)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0d9e048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "if ENVIR == 'indoor':\n",
    "    mat = sio.loadmat('../../DataSpace/csinet/data/DATA_Htrainin.mat')\n",
    "    x_train = mat['HT']  # array\n",
    "    mat = sio.loadmat('../../DataSpace/csinet/data/DATA_Hvalin.mat')\n",
    "    x_val = mat['HT']  # array\n",
    "    mat = sio.loadmat('../../DataSpace/csinet/data/DATA_Htestin.mat')\n",
    "    x_test = mat['HT']  # array\n",
    "\n",
    "elif ENVIR == 'outdoor':\n",
    "    mat = sio.loadmat('../../DataSpace/csinet/data/DATA_Htrainout.mat')\n",
    "    x_train = mat['HT']  # array\n",
    "    mat = sio.loadmat('../../DataSpace/csinet/data/DATA_Hvalout.mat')\n",
    "    x_val = mat['HT']  # array\n",
    "    mat = sio.loadmat('../../DataSpace/csinet/data/DATA_Htestout.mat')\n",
    "    x_test = mat['HT']  # array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cdcbb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train 的原始维度: (100000, 2048)\n",
      "x_train 的塑形维度: (100000, 2, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "print('x_train 的原始维度:', x_train.shape)\n",
    "\n",
    "x_train = np.reshape(x_train, (len(x_train), CHANNELS, IMG_HEIGHT, IMG_WIDTH))\n",
    "x_val = np.reshape(x_val, (len(x_val), CHANNELS, IMG_HEIGHT, IMG_WIDTH))\n",
    "x_test = np.reshape(x_test, (len(x_test), CHANNELS, IMG_HEIGHT, IMG_WIDTH))\n",
    "print('x_train 的塑形维度:', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1caaca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "classical_nn = ClassicalNN(channels=CHANNELS, img_height=IMG_HEIGHT, com_height=COM_HEIGHT)\n",
    "hybrid_nn = HybridNN(classical_nn=classical_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bb4849d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (numpy.ndarray, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!numpy.ndarray!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = \"valid\", tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!numpy.ndarray!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m hybrid_nn(x_test[\u001b[32m0\u001b[39m:\u001b[32m1\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/penny/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/penny/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mHybridNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m      9\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m''' 在量子线路前，加上经典压缩网络 '''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     com_params = \u001b[38;5;28mself\u001b[39m.classical_nn(x)\n\u001b[32m     11\u001b[39m     reverse_x = (-\u001b[32m1\u001b[39m) * x\n\u001b[32m     12\u001b[39m     loss = frqi_circuit(com_params, reverse_x, \u001b[38;5;28mself\u001b[39m.asz_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/penny/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/penny/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mClassicalNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     13\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m''' 定义经典压缩层 '''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.conv(x)\n\u001b[32m     15\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.leaky_relu(x)\n\u001b[32m     16\u001b[39m     x = x.reshape((x.shape[\u001b[32m0\u001b[39m], \u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.img_dim))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/penny/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/penny/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/penny/lib/python3.11/site-packages/torch/nn/modules/conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m.weight, \u001b[38;5;28mself\u001b[39m.bias)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/penny/lib/python3.11/site-packages/torch/nn/modules/conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    544\u001b[39m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m.stride, \u001b[38;5;28mself\u001b[39m.padding, \u001b[38;5;28mself\u001b[39m.dilation, \u001b[38;5;28mself\u001b[39m.groups\n\u001b[32m    545\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: conv2d() received an invalid combination of arguments - got (numpy.ndarray, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!numpy.ndarray!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = \"valid\", tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!numpy.ndarray!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n"
     ]
    }
   ],
   "source": [
    "hybrid_nn(x_test[0:1])  # 测试前向传播是否成功"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e57a693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penny",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
