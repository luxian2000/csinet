import pennylane as qml
import numpy as np
import torch
from torch import nn
import scipy.io as sio
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader, TensorDataset
import time

# Global parameters
ENVIR = 'indoor'
LAYERS = 2
BATCHES = 5
CHANNELS = 2

# image parameters
IMG_HEIGHT = 32
IMG_WIDTH = IMG_HEIGHT
IMG_DIM = IMG_HEIGHT * IMG_WIDTH * CHANNELS
IMG_QUBITS = int(np.log2(IMG_DIM))

# compressed parameters
COM_HEIGHT = 16
COM_WIDTH = COM_HEIGHT 
COM_DIM = COM_HEIGHT * COM_WIDTH * CHANNELS
COM_QUBITS = int(np.log2(COM_DIM))

ALL_QUBITS = IMG_QUBITS + 1
ANC_QUBITS = IMG_QUBITS - COM_QUBITS


class ClassicalNN(nn.Module):
    ''' æ„é€ ç»å…¸å‹ç¼©ç¥ç»ç½‘ç»œ '''
    def __init__(self, channels, img_height, com_height):
        super().__init__()
        self.img_dim = channels * img_height**2
        self.com_dim = channels * com_height**2
        self.conv = nn.Conv2d(in_channels=channels, out_channels=2, kernel_size=3, stride=1, padding=1, bias=True)
        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)
        self.dense_encode = nn.Linear(in_features=self.img_dim, out_features=self.com_dim)
        self.bn1d = nn.BatchNorm1d(num_features=channels)

    def forward(self, x):
        ''' å®šä¹‰ç»å…¸å‹ç¼©å±‚ '''
        x = self.conv(x)
        x = self.leaky_relu(x)
        x = x.reshape((x.shape[0], -1))  # å±•å¹³
        x = self.dense_encode(x)
        x = self.bn1d(x) * 2
        return x


def frqi_encoder(qubits, params):
    ''' construct the FRQI encoding circuit '''
    for index in range(2**qubits):
        binary_str = bin(index)[2:].zfill(qubits)  # è¡¥é›¶ç¡®ä¿é•¿åº¦ä¸€è‡´
        bits = [int(bit) for bit in binary_str]
        bits.reverse()
        # ä½¿ç”¨æ¡ä»¶æ§åˆ¶é—¨
        control_wires = [i+1 for i, bit in enumerate(bits) if bit == 1]
        control_values = [1] * len(control_wires)
        if control_wires:
            qml.ctrl(qml.RY, control=control_wires, control_values=control_values)(params[index], wires=0)
        else:
            qml.RY(params[index], wires=0)


coe = [-1]
obs_list = [qml.PauliZ(0)]
hamiltonian = qml.Hamiltonian(coe, observables=obs_list)

dev = qml.device('default.qubit', wires=ALL_QUBITS)


@qml.qnode(dev, interface='torch')
def frqi_circuit(com_qubits, com_params, img_qubits, img_params, asz_params):
    ''' construct the complete quantum circuit '''
    # åˆå§‹åŒ–è¾…åŠ©é‡å­æ¯”ç‰¹
    qml.Hadamard(wires=0)
    
    frqi_encoder(com_qubits, com_params)
    qml.StronglyEntanglingLayers(weights=asz_params, wires=range(ALL_QUBITS))
    frqi_encoder(img_qubits, img_params)
    return qml.expval(hamiltonian)


class HybridNN(nn.Module):
    ''' æŠŠä¸Šé¢å®šä¹‰çš„ç»å…¸ç¥ç»ç½‘ç»œå’Œé‡å­ç¥ç»ç½‘ç»œç»„è£…æˆå®Œæ•´ç¥ç»ç½‘ç»œ '''
    def __init__(self, classical_nn, com_qubits, img_qubits):
        super().__init__()
        self.classical_nn = classical_nn
        self.com_qubits = com_qubits
        self.img_qubits = img_qubits
        self.all_qubits = img_qubits + 1
        
        # å°†asz_paramsè½¬æ¢ä¸ºå¯è®­ç»ƒå‚æ•°
        asz_params = np.random.uniform(0, np.pi, size=(LAYERS, self.all_qubits, 3))
        self.asz_params = nn.Parameter(torch.tensor(asz_params, dtype=torch.float32))

    def forward(self, x):
        # ç»å…¸ç¥ç»ç½‘ç»œå¤„ç†
        com_params = self.classical_nn(x)
        
        # å°†è¾“å…¥æ•°æ®å±•å¹³ç”¨äºé‡å­ç¼–ç 
        batch_size = x.shape[0]
        x_flat = x.reshape(batch_size, -1)
        
        # å¯¹batchä¸­çš„æ¯ä¸ªæ ·æœ¬å•ç‹¬å¤„ç†
        energies = []
        for i in range(batch_size):
            current_com_params = com_params[i]
            current_img_params = x_flat[i]
            
            # è¿è¡Œé‡å­ç”µè·¯
            energy = frqi_circuit(
                self.com_qubits, 
                current_com_params, 
                self.img_qubits, 
                current_img_params, 
                self.asz_params
            )
            energies.append(energy)
        
        return torch.stack(energies)


# Data loading
if ENVIR == 'indoor':
    mat = sio.loadmat('../../DataSpace/csinet/data/DATA_Htrainin.mat')
    x_train = mat['HT']  # array
    mat = sio.loadmat('../../DataSpace/csinet/data/DATA_Hvalin.mat')
    x_val = mat['HT']  # array
    mat = sio.loadmat('../../DataSpace/csinet/data/DATA_Htestin.mat')
    x_test = mat['HT']  # array

elif ENVIR == 'outdoor':
    mat = sio.loadmat('../../DataSpace/csinet/data/DATA_Htrainout.mat')
    x_train = mat['HT']  # array
    mat = sio.loadmat('../../DataSpace/csinet/data/DATA_Hvalout.mat')
    x_val = mat['HT']  # array
    mat = sio.loadmat('../../DataSpace/csinet/data/DATA_Htestout.mat')
    x_test = mat['HT']  # array

x_train = x_train.astype('float32')
x_val = x_val.astype('float32')
x_test = x_test.astype('float32')
print('x_train çš„åŸå§‹ç»´åº¦:', x_train.shape)

x_train = np.reshape(x_train, (len(x_train), CHANNELS, IMG_HEIGHT, IMG_WIDTH))
x_val = np.reshape(x_val, (len(x_val), CHANNELS, IMG_HEIGHT, IMG_WIDTH))
x_test = np.reshape(x_test, (len(x_test), CHANNELS, IMG_HEIGHT, IMG_WIDTH))
print('x_train çš„å¡‘å½¢ç»´åº¦:', x_train.shape)


def train_hybrid_nn():
    ''' è®­ç»ƒæ··åˆç¥ç»ç½‘ç»œ '''
    # åˆå§‹åŒ–æ¨¡å‹
    classical_nn = ClassicalNN(channels=CHANNELS, img_height=IMG_HEIGHT, com_height=COM_HEIGHT)
    hybrid_nn = HybridNN(classical_nn=classical_nn, com_qubits=COM_QUBITS, img_qubits=IMG_QUBITS)

    # æ£€æŸ¥å¯è®­ç»ƒå‚æ•°
    print("å¯è®­ç»ƒå‚æ•°:")
    for name, param in hybrid_nn.named_parameters():
        if param.requires_grad:
            print(f"{name}: {param.shape}")
    
    total_params = sum(p.numel() for p in hybrid_nn.parameters() if p.requires_grad)
    print(f"æ€»å¯è®­ç»ƒå‚æ•°æ•°: {total_params}")

    # ä¼˜åŒ–å™¨ - åŒæ—¶ä¼˜åŒ–classical_nnå’Œasz_params
    optimizer = torch.optim.Adam(hybrid_nn.parameters(), lr=0.001)
    
    # æŸå¤±å‡½æ•° - ä½¿ç”¨MSEæŸå¤±ï¼Œç›®æ ‡æ˜¯ä½¿é‡å­ç”µè·¯è¾“å‡ºæ¥è¿‘æŸä¸ªç›®æ ‡å€¼
    criterion = nn.MSELoss()
    
    # æ•°æ®å‡†å¤‡
    x_train_tensor = torch.tensor(x_train)
    x_val_tensor = torch.tensor(x_val)
    x_test_tensor = torch.tensor(x_test)
    
    # åˆ›å»ºç›®æ ‡å€¼ï¼ˆè¿™é‡Œå‡è®¾æˆ‘ä»¬å¸Œæœ›é‡å­ç”µè·¯è¾“å‡ºæ¥è¿‘0ï¼‰
    # æ‚¨å¯ä»¥æ ¹æ®å…·ä½“ä»»åŠ¡è°ƒæ•´ç›®æ ‡å€¼
    target_value = 0.0
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_dataset = TensorDataset(x_train_tensor, torch.full((len(x_train_tensor),), target_value))
    train_loader = DataLoader(train_dataset, batch_size=BATCHES, shuffle=True)
    
    # è®­ç»ƒå‚æ•°
    num_epochs = 100
    best_loss = float('inf')
    train_losses = []
    val_losses = []
    
    print("å¼€å§‹è®­ç»ƒæ··åˆé‡å­-ç»å…¸ç¥ç»ç½‘ç»œ...")
    print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(x_train)}")
    print(f"æ‰¹æ¬¡å¤§å°: {BATCHES}")
    print(f"ç›®æ ‡å€¼: {target_value}")
    
    start_time = time.time()
    
    for epoch in range(num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        hybrid_nn.train()
        epoch_train_loss = 0.0
        num_batches = 0
        
        for batch_idx, (data, target) in enumerate(train_loader):
            optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            outputs = hybrid_nn(data)
            
            # è®¡ç®—æŸå¤± - ä½¿é‡å­ç”µè·¯è¾“å‡ºæ¥è¿‘ç›®æ ‡å€¼
            loss = criterion(outputs, torch.full_like(outputs, target_value))
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
            torch.nn.utils.clip_grad_norm_(hybrid_nn.parameters(), max_norm=1.0)
            
            # å‚æ•°æ›´æ–°
            optimizer.step()
            
            epoch_train_loss += loss.item()
            num_batches += 1
            
            if batch_idx % 10 == 0:
                print(f'Epoch {epoch+1:03d}/{num_epochs:03d} | '
                      f'Batch {batch_idx:03d}/{len(train_loader):03d} | '
                      f'Loss: {loss.item():.6f}')
        
        avg_train_loss = epoch_train_loss / num_batches if num_batches > 0 else 0
        train_losses.append(avg_train_loss)
        
        # éªŒè¯é˜¶æ®µ
        hybrid_nn.eval()
        with torch.no_grad():
            val_outputs = hybrid_nn(x_val_tensor)
            val_loss = criterion(val_outputs, torch.full_like(val_outputs, target_value)).item()
            val_losses.append(val_loss)
        
        # å­¦ä¹ ç‡è°ƒåº¦ï¼ˆå¯é€‰ï¼‰
        if epoch > 0 and epoch % 20 == 0:
            for param_group in optimizer.param_groups:
                param_group['lr'] *= 0.5
            print(f"å­¦ä¹ ç‡è°ƒæ•´ä¸º: {optimizer.param_groups[0]['lr']}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_loss < best_loss:
            best_loss = val_loss
            torch.save({
                'epoch': epoch,
                'model_state_dict': hybrid_nn.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'train_loss': avg_train_loss,
                'val_loss': val_loss,
            }, 'best_hybrid_model.pth')
            print(f'âœ… ä¿å­˜æœ€ä½³æ¨¡å‹åœ¨å‘¨æœŸ {epoch+1}, éªŒè¯æŸå¤±: {val_loss:.6f}')
        
        print(f'Epoch {epoch+1:03d}/{num_epochs:03d} | '
              f'è®­ç»ƒæŸå¤±: {avg_train_loss:.6f} | '
              f'éªŒè¯æŸå¤±: {val_loss:.6f}')
        
        # æ—©åœæ£€æŸ¥
        if epoch > 10 and val_loss > np.mean(val_losses[-5:]):
            print("âš ï¸  éªŒè¯æŸå¤±ä¸Šå‡ï¼Œè€ƒè™‘æ—©åœ...")
            if epoch > 30:  # è‡³å°‘è®­ç»ƒ30ä¸ªå‘¨æœŸ
                break
    
    training_time = time.time() - start_time
    print(f'ğŸ‰ è®­ç»ƒå®Œæˆ! æ€»æ—¶é—´: {training_time:.2f}ç§’')
    
    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    plt.figure(figsize=(10, 6))
    plt.plot(train_losses, label='è®­ç»ƒæŸå¤±', alpha=0.7)
    plt.plot(val_losses, label='éªŒè¯æŸå¤±', alpha=0.7)
    plt.xlabel('è®­ç»ƒå‘¨æœŸ')
    plt.ylabel('æŸå¤±å€¼')
    plt.title('æ··åˆé‡å­-ç»å…¸ç¥ç»ç½‘ç»œè®­ç»ƒè¿‡ç¨‹')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig('training_curve.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # æµ‹è¯•æ¨¡å‹
    test_model(hybrid_nn, x_test_tensor, target_value)
    
    return hybrid_nn, train_losses, val_losses


def test_model(model, test_data, target_value):
    """æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹"""
    model.eval()
    criterion = nn.MSELoss()
    
    with torch.no_grad():
        test_outputs = model(test_data)
        test_loss = criterion(test_outputs, torch.full_like(test_outputs, target_value)).item()
        
        print(f'\nğŸ“Š æµ‹è¯•ç»“æœ:')
        print(f'æµ‹è¯•æŸå¤±: {test_loss:.6f}')
        print(f'è¾“å‡ºèŒƒå›´: [{test_outputs.min().item():.3f}, {test_outputs.max().item():.3f}]')
        print(f'è¾“å‡ºå‡å€¼: {test_outputs.mean().item():.3f} Â± {test_outputs.std().item():.3f}')
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªæ ·æœ¬çš„è¾“å‡º
        print(f'å‰5ä¸ªæ ·æœ¬è¾“å‡º: {test_outputs[:5].squeeze().tolist()}')


def load_and_evaluate(model_path, x_test):
    """åŠ è½½ä¿å­˜çš„æ¨¡å‹å¹¶è¿›è¡Œè¯„ä¼°"""
    classical_nn = ClassicalNN(channels=CHANNELS, img_height=IMG_HEIGHT, com_height=COM_HEIGHT)
    model = HybridNN(classical_nn=classical_nn, com_qubits=COM_QUBITS, img_qubits=IMG_QUBITS)
    
    checkpoint = torch.load(model_path)
    model.load_state_dict(checkpoint['model_state_dict'])
    
    print(f"âœ… åŠ è½½æ¨¡å‹å®Œæˆï¼Œè®­ç»ƒå‘¨æœŸ: {checkpoint['epoch'] + 1}")
    print(f"è®­ç»ƒæŸå¤±: {checkpoint['train_loss']:.6f}")
    print(f"éªŒè¯æŸå¤±: {checkpoint['val_loss']:.6f}")
    
    x_test_tensor = torch.tensor(x_test)
    test_model(model, x_test_tensor, target_value=0.0)
    
    return model


if __name__ == "__main__":
    # å¼€å§‹è®­ç»ƒ
    print("ğŸš€ å¯åŠ¨æ··åˆé‡å­-ç»å…¸ç¥ç»ç½‘ç»œè®­ç»ƒ...")
    trained_model, train_losses, val_losses = train_hybrid_nn()
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    torch.save(trained_model.state_dict(), 'final_hybrid_model.pth')
    print("ğŸ’¾ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜!")
    
    # å¯é€‰ï¼šåŠ è½½å¹¶è¯„ä¼°æœ€ä½³æ¨¡å‹
    try:
        print("\nğŸ” è¯„ä¼°æœ€ä½³æ¨¡å‹...")
        best_model = load_and_evaluate('best_hybrid_model.pth', x_test)
    except Exception as e:
        print(f"åŠ è½½æœ€ä½³æ¨¡å‹æ—¶å‡ºé”™: {e}")
